# scripts/train_value_weight_models.py

"""
Train value and weight prediction models for MS-MEQE.

Uses training data generated by create_training_data_msmeqe.py
Trains XGBoost regressors as described in Sections 3.3.2 and 3.4.2

Usage:
    python scripts/train_value_weight_models.py \\
        --value-data data/training_data/value_training_data.pkl \\
        --weight-data data/training_data/weight_training_data.pkl \\
        --output-dir models/ \\
        --n-estimators 100 \\
        --max-depth 6 \\
        --learning-rate 0.1
"""

import logging
import argparse
from pathlib import Path
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import pickle
import json

logger = logging.getLogger(__name__)


def load_pickle(path: str):
    """Load pickle file (fallback if utils not available)."""
    with open(path, 'rb') as f:
        return pickle.load(f)


def train_value_model(
        training_data_path: str,
        output_path: str,
        n_estimators: int = 100,
        max_depth: int = 6,
        learning_rate: float = 0.1,
):
    """
    Train value prediction model.

    Value model predicts Δ_MAP for expansion candidates.
    Features: 18 features from Section 3.3.1
    Target: Δ_MAP (change in MAP when adding term)

    Args:
        training_data_path: Path to value_training_data.pkl
        output_path: Where to save trained model
        n_estimators: Number of trees
        max_depth: Maximum tree depth
        learning_rate: XGBoost learning rate
    """
    logger.info(f"Loading value training data from {training_data_path}")

    try:
        data = load_pickle(training_data_path)
    except Exception as e:
        logger.error(f"Failed to load training data: {e}")
        raise

    X = data['features']  # Shape: (n_instances, 18)
    y = data['targets']  # Shape: (n_instances,)

    logger.info(f"Value training data: {X.shape[0]} instances, {X.shape[1]} features")
    logger.info(f"Target stats: mean={y.mean():.4f}, std={y.std():.4f}, "
                f"min={y.min():.4f}, max={y.max():.4f}")

    # Split into train/validation
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    logger.info(f"Train: {len(X_train)} instances, Val: {len(X_val)} instances")

    # Train XGBoost regressor
    logger.info("Training XGBoost value model...")
    logger.info(f"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, "
                f"learning_rate={learning_rate}")

    model = xgb.XGBRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1,  # Use all CPU cores
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        eval_metric=['rmse', 'mae'],
        verbose=True,
    )

    # Comprehensive evaluation
    logger.info("\n" + "=" * 60)
    logger.info("VALUE MODEL EVALUATION")
    logger.info("=" * 60)

    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)

    # Training metrics
    train_r2 = r2_score(y_train, y_train_pred)
    train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)
    train_mae = mean_absolute_error(y_train, y_train_pred)

    logger.info(f"\nTraining Metrics:")
    logger.info(f"  R²:   {train_r2:.4f}")
    logger.info(f"  RMSE: {train_rmse:.4f}")
    logger.info(f"  MAE:  {train_mae:.4f}")

    # Validation metrics
    val_r2 = r2_score(y_val, y_val_pred)
    val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)
    val_mae = mean_absolute_error(y_val, y_val_pred)

    logger.info(f"\nValidation Metrics:")
    logger.info(f"  R²:   {val_r2:.4f}")
    logger.info(f"  RMSE: {val_rmse:.4f}")
    logger.info(f"  MAE:  {val_mae:.4f}")

    # Feature importance with names
    importance = model.feature_importances_

    # Feature names from Section 3.3.1
    feature_names = [
        'cos_sim_q',  # 0
        'cos_sim_pseudo',  # 1
        'l2_dist_q',  # 2
        'idf',  # 3
        'tf_pseudo',  # 4
        'rm3_score',  # 5
        'coverage_pseudo',  # 6
        'in_query',  # 7
        'jaccard',  # 8
        'pmi_max',  # 9
        'bm25_delta',  # 10
        'clarity_delta',  # 11
        'source_docs',  # 12
        'source_kb',  # 13
        'source_emb',  # 14
        'native_rank_norm',  # 15
        'native_score',  # 16
        'extra_17',  # 17 (if you have 18 features)
    ]

    logger.info("\nTop 10 Features by Importance:")
    top_indices = np.argsort(importance)[::-1][:10]
    for i, idx in enumerate(top_indices, 1):
        fname = feature_names[idx] if idx < len(feature_names) else f"Feature_{idx}"
        logger.info(f"  {i:2d}. {fname:20s}: {importance[idx]:.4f}")

    # Save model
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    joblib.dump(model, output_path)
    logger.info(f"\nValue model saved to {output_path}")

    # Save metrics
    metrics = {
        'train': {'r2': float(train_r2), 'rmse': float(train_rmse), 'mae': float(train_mae)},
        'val': {'r2': float(val_r2), 'rmse': float(val_rmse), 'mae': float(val_mae)},
        'feature_importance': {
            feature_names[i] if i < len(feature_names) else f"Feature_{i}": float(importance[i])
            for i in range(len(importance))
        },
    }

    metrics_path = output_path.parent / "value_model_metrics.json"
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    logger.info(f"Metrics saved to {metrics_path}")

    return model


def train_weight_model(
        training_data_path: str,
        output_path: str,
        n_estimators: int = 100,
        max_depth: int = 6,
        learning_rate: float = 0.1,
):
    """
    Train weight prediction model.

    Weight model predicts risk/cost for expansion candidates.
    Features: 20 features from Section 3.4.1
    Target: max(0, -Δ_MAP) (risk of negative impact)

    Args:
        training_data_path: Path to weight_training_data.pkl
        output_path: Where to save trained model
        n_estimators: Number of trees
        max_depth: Maximum tree depth
        learning_rate: XGBoost learning rate
    """
    logger.info(f"Loading weight training data from {training_data_path}")

    try:
        data = load_pickle(training_data_path)
    except Exception as e:
        logger.error(f"Failed to load training data: {e}")
        raise

    X = data['features']  # Shape: (n_instances, 20)
    y = data['targets']  # Shape: (n_instances,)

    logger.info(f"Weight training data: {X.shape[0]} instances, {X.shape[1]} features")
    logger.info(f"Target stats: mean={y.mean():.4f}, std={y.std():.4f}, "
                f"min={y.min():.4f}, max={y.max():.4f}")

    # Split into train/validation
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    logger.info(f"Train: {len(X_train)} instances, Val: {len(X_val)} instances")

    # Train XGBoost regressor
    logger.info("Training XGBoost weight model...")
    logger.info(f"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, "
                f"learning_rate={learning_rate}")

    model = xgb.XGBRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1,  # Use all CPU cores
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        eval_metric=['rmse', 'mae'],
        verbose=True,
    )

    # Comprehensive evaluation
    logger.info("\n" + "=" * 60)
    logger.info("WEIGHT MODEL EVALUATION")
    logger.info("=" * 60)

    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)

    # Training metrics
    train_r2 = r2_score(y_train, y_train_pred)
    train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)
    train_mae = mean_absolute_error(y_train, y_train_pred)

    logger.info(f"\nTraining Metrics:")
    logger.info(f"  R²:   {train_r2:.4f}")
    logger.info(f"  RMSE: {train_rmse:.4f}")
    logger.info(f"  MAE:  {train_mae:.4f}")

    # Validation metrics
    val_r2 = r2_score(y_val, y_val_pred)
    val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)
    val_mae = mean_absolute_error(y_val, y_val_pred)

    logger.info(f"\nValidation Metrics:")
    logger.info(f"  R²:   {val_r2:.4f}")
    logger.info(f"  RMSE: {val_rmse:.4f}")
    logger.info(f"  MAE:  {val_mae:.4f}")

    # Feature importance with names
    importance = model.feature_importances_

    # Feature names from Section 3.4.1
    feature_names = [
        'cos_sim_q',  # 0 - Drift features
        'l2_dist_q',  # 1
        'edit_dist',  # 2
        'df_norm',  # 3 - Ambiguity features
        'cf_norm',  # 4
        'idf',  # 5
        'polysemy',  # 6
        'coverage',  # 7
        'source_docs',  # 8 - Source risk features
        'source_kb',  # 9
        'source_emb',  # 10
        'native_rank',  # 11
        'native_score',  # 12
        'source_confidence',  # 13
        'rm3_score',  # 14
        'term_len_norm',  # 15 - Additional risk signals
        'is_stopword',  # 16
        'in_query',  # 17
        'char_diversity',  # 18
        'has_numbers',  # 19
    ]

    logger.info("\nTop 10 Features by Importance:")
    top_indices = np.argsort(importance)[::-1][:10]
    for i, idx in enumerate(top_indices, 1):
        fname = feature_names[idx] if idx < len(feature_names) else f"Feature_{idx}"
        logger.info(f"  {i:2d}. {fname:20s}: {importance[idx]:.4f}")

    # Save model
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    joblib.dump(model, output_path)
    logger.info(f"\nWeight model saved to {output_path}")

    # Save metrics
    metrics = {
        'train': {'r2': float(train_r2), 'rmse': float(train_rmse), 'mae': float(train_mae)},
        'val': {'r2': float(val_r2), 'rmse': float(val_rmse), 'mae': float(val_mae)},
        'feature_importance': {
            feature_names[i] if i < len(feature_names) else f"Feature_{i}": float(importance[i])
            for i in range(len(importance))
        },
    }

    metrics_path = output_path.parent / "weight_model_metrics.json"
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    logger.info(f"Metrics saved to {metrics_path}")

    return model


def main():
    """Main entry point for training value/weight models."""
    parser = argparse.ArgumentParser(
        description="Train MS-MEQE value/weight models",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument("--value-data", type=str, required=True,
                        help="Path to value_training_data.pkl")
    parser.add_argument("--weight-data", type=str, required=True,
                        help="Path to weight_training_data.pkl")
    parser.add_argument("--output-dir", type=str, required=True,
                        help="Output directory for models")

    # Hyperparameters
    parser.add_argument("--n-estimators", type=int, default=100,
                        help="Number of XGBoost trees")
    parser.add_argument("--max-depth", type=int, default=6,
                        help="Maximum tree depth")
    parser.add_argument("--learning-rate", type=float, default=0.1,
                        help="XGBoost learning rate")

    args = parser.parse_args()

    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] %(levelname)s %(name)s: %(message)s'
    )

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("=" * 60)
    logger.info("MS-MEQE MODEL TRAINING")
    logger.info("=" * 60)
    logger.info(f"Value data:  {args.value_data}")
    logger.info(f"Weight data: {args.weight_data}")
    logger.info(f"Output dir:  {args.output_dir}")
    logger.info("")

    # Train value model
    logger.info("STEP 1: Training Value Model")
    logger.info("-" * 60)
    value_model = train_value_model(
        training_data_path=args.value_data,
        output_path=output_dir / "value_model.pkl",
        n_estimators=args.n_estimators,
        max_depth=args.max_depth,
        learning_rate=args.learning_rate,
    )

    logger.info("\n")

    # Train weight model
    logger.info("STEP 2: Training Weight Model")
    logger.info("-" * 60)
    weight_model = train_weight_model(
        training_data_path=args.weight_data,
        output_path=output_dir / "weight_model.pkl",
        n_estimators=args.n_estimators,
        max_depth=args.max_depth,
        learning_rate=args.learning_rate,
    )

    logger.info("\n" + "=" * 60)
    logger.info("TRAINING COMPLETE!")
    logger.info("=" * 60)
    logger.info(f"Models saved to: {output_dir}")
    logger.info("  - value_model.pkl")
    logger.info("  - weight_model.pkl")
    logger.info("  - value_model_metrics.json")
    logger.info("  - weight_model_metrics.json")
    logger.info("")
    logger.info("Next step: Train budget model")
    logger.info(f"  python scripts/train_budget_model.py \\")
    logger.info(f"    --value-model {output_dir}/value_model.pkl \\")
    logger.info(f"    --weight-model {output_dir}/weight_model.pkl \\")
    logger.info(f"    ...")


if __name__ == "__main__":
    main()